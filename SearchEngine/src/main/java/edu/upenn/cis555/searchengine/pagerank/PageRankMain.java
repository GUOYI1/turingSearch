package cs3.cs2.cs.searchengine.pagerank;

import java.io.BufferedReader;
import java.io.File;
import java.io.InputStreamReader;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.ToolRunner;

public class PageRankMain {
	
	// total number of files
	public static int total = 0;
	// maximum iterations
	private static final int maxIter = 40;
	// check converge every (frequency) iterations
	private static final int frequency = 5;

	public static void main(String[] args) throws Exception {
		if (args.length != 2) {
			System.out.println("Usage: <input dir> <output dir>");
			System.exit(-1);
		}

		String inputDir = args[0];
		String outputDir = args[1];
//		String tempDir = outputDir + "/preprocess";
//		ToolRunner.run(new Preprocessing(), new String[] { inputDir, tempDir } ) ;
		
		String tempDir = outputDir + "/remove";
		if (ToolRunner.run(new RemoveDanglings(), new String[] { inputDir, tempDir } ) == 1) {
			System.err.println("Remove dangling error");
			System.exit(-1);
		}
		
		// read the total number of pages from hdfs file generated by previous step
		// fs is local hdfs file system not s3.
		FileSystem fs = FileSystem.get(new Configuration());
		Path totalPath = new Path("/total");
		total = fs.open(totalPath).readInt();
		
		inputDir = tempDir;
		tempDir = outputDir + "/init";
		if (ToolRunner.run(new Initialization(), new String[] { inputDir, tempDir } ) == 1) {
			System.err.println("init error");
			System.exit(-1);
		}
		
//		System.out.println("now total:" + total);
		
		
		double error = 0;
		int i;
		for (i = 1; i <= maxIter; i++) {
			inputDir = tempDir;
			tempDir = outputDir + "/iter" + i;
			// one iteration
			if (ToolRunner.run(new PageRankIteration(), new String[] { inputDir, tempDir, String.valueOf(i) } ) == 1) {
				System.err.println("iter" + i + " error");
				System.exit(-1);
			};
			
			// check converge every frequency interation
			if (i % frequency == 0) {
				error = 0;
				if (ToolRunner.run(new Convergence(), new String[] { tempDir, outputDir + File.separator + "converge" + String.valueOf(i), String.valueOf(i) } ) == 1) {
					System.err.println("converge" + i + " error");
					System.exit(-1);
				};
				// read error from corresponding hdfs file
				Path convergePath = new Path("/converge" + String.valueOf(i) + File.separator + "converge" + String.valueOf(i) + "-r-00000");
				BufferedReader in = new BufferedReader(new InputStreamReader(fs.open(convergePath)));
				error = Double.parseDouble(in.readLine());
				
				// TODO add threshold
				// if smaller than the threshold, break the loop
				if (error/total < 0.0000001) {
					break;
				}
			}
		}
		
		if (ToolRunner.run(new FinalStep(), new String[] { tempDir, outputDir + "/final"}) == 1) {
			System.err.println("final step: error");
			System.exit(-1);
		}
		
		System.out.println("total error: " + error);
		System.out.println("total doc: " + total);
		System.out.println("average error: " + error / total);
		System.out.println("total iteration: " + i);
		
	}
}
